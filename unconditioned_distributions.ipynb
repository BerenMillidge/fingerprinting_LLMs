{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "\n",
    "def completion(model, prompt, length, temperature, tokenizer, print_output = True):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(inputs, max_length = length, temperature = temperature)\n",
    "    decoded_prompt = tokenizer.decode(inputs[0])\n",
    "    p = colored(tokenizer.decode(inputs[0]),'green')\n",
    "    output_str = tokenizer.decode(outputs[0])\n",
    "    g = colored(output_str[len(decoded_prompt):], 'red')\n",
    "    if print_output:\n",
    "        print(p + g)\n",
    "    output_tokens = outputs[0][len(inputs[0]):]\n",
    "    return output_str, output_tokens\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|endoftext|>\u001b[0m\u001b[31mThe first time I saw the movie, I was in my early twenties, and I was so excited to see it. I was so excited to see it because I had seen it in theaters, and I had seen it on TV, and I had seen it on the radio, and I had seen it on the internet. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see it. I was so excited to see\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"<|endoftext|>\"\n",
    "temperature = 0.0\n",
    "length = 200\n",
    "output_str, output_tokens = completion(model, prompt, length, temperature, tokenizer, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a8375c4f6f450bb17eed1d14fbedcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7689c07a55242cf8bf5b05cf527b135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1032aff4d57044489a5cc685856a88fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d534d350e340ca811832b0d2d15758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55860bafb5f24c3fb9a2e9125b9949bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|endoftext|>\u001b[0m\u001b[31mThe U.S. Department of Justice has filed a civil rights lawsuit against the city of Ferguson, Missouri, and the police department, alleging that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit, filed in U.S. District Court in St. Louis, alleges that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit alleges that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit alleges that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit alleges that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit alleges that the police department has engaged in a pattern or practice of excessive force and unconstitutional searches and seizures.\n",
      "\n",
      "The lawsuit alleges that the police department has engaged in\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-large\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"<|endoftext|>\"\n",
    "temperature = 0.0\n",
    "length = 200\n",
    "output_str, output_tokens = completion(model, prompt, length, temperature, tokenizer, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf617ff664ff40cfbd906a12ebee5c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985ed8661c4b4e7289f0e088fccd64c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfed70fc736427bb5aad6082e062996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71ff2a327f84b1fa6f5301aecfa28f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a476a487ab14e51ab27a9979b80c064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|endoftext|>\u001b[0m\u001b[31mThe first time I saw the movie, I was in the middle of a long day of work. I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of work, and I was in the middle of a long day of\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"<|endoftext|>\"\n",
    "temperature = 0.0\n",
    "length = 200\n",
    "output_str, output_tokens = completion(model, prompt, length, temperature, tokenizer, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25592b8dd6b4993854dbd788c614bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dac39fbe5644336b38cb7ae50f56368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080ff32d347948aeac0a6d540b8c11b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0fc8aa40044d34a67ad65084cc401c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81e887efc5a4b12a739b2001a7437e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|endoftext|>\u001b[0m\u001b[31m\n",
      "The first time I saw the new version of the game, I was so excited. I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game, I was so excited to see the new version of the game\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"<|endoftext|>\"\n",
    "temperature = 0.0\n",
    "length = 200\n",
    "output_str, output_tokens = completion(model, prompt, length, temperature, tokenizer, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|endoftext|>\u001b[0m\u001b[31mQ:\n",
      "\n",
      "How to get the value of a variable in a function in C?\n",
      "\n",
      "I have a function that is supposed to return the value of a variable.\n",
      "int get_value(int *value)\n",
      "{\n",
      "    *value = 5;\n",
      "    return *value;\n",
      "}\n",
      "\n",
      "int main()\n",
      "{\n",
      "    int value = 0;\n",
      "    printf(\"%d\", get_value(&value));\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "I get a warning:\n",
      "warning: format ‘%d’ expects argument of type ‘int *’, but argument 2 has type ‘int’ [-Wformat=]\n",
      "\n",
      "I don't understand why.\n",
      "\n",
      "A:\n",
      "\n",
      "You need to pass the address of the variable to the function.\n",
      "int get_value(int *value)\n",
      "{\n",
      "    *value = 5;\n",
      "  \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTJForCausalLM\n",
    "\n",
    "model = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", revision=\"float16\", torch_dtype=torch.float16, low_cpu_mem_usage=False).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "prompt = \"<|endoftext|>\"\n",
    "temperature = 0.0\n",
    "length = 200\n",
    "output_str, output_tokens = completion(model, prompt, length, temperature, tokenizer, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
